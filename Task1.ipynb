{
 "cells": [
  {
   "cell_type": "code",
   "id": "554aaa1d-993a-4039-9d08-d6d29b4a3dfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:02:22.471966Z",
     "start_time": "2025-04-20T10:02:18.114054Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "706a8e8f-3b19-40aa-a74d-b3ab9d7709ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:02:22.575972Z",
     "start_time": "2025-04-20T10:02:22.486385Z"
    }
   },
   "source": [
    "image_path = \"images1/images/\"\n",
    "image_processed_path = \"images1/images_processed/\"\n",
    "os.makedirs(image_processed_path, exist_ok=True)\n",
    "\n",
    "\n",
    "model = YOLO(\"yolov10n.pt\")\n",
    "\n",
    "confidence_threshold = 0.8\n",
    "people_true_number = [5, 3, 4, 4, 6, 5, 4, 4, 4, 5]\n",
    "output_size = (640, 640)\n",
    "results_array = []\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:03:08.083419Z",
     "start_time": "2025-04-20T10:02:22.596789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for image_number in range(0, 10):\n",
    "    image_file = f\"{image_path}{image_number}.jpg\"\n",
    "    image = cv2.imread(image_file)\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"Ошибка: не удалось загрузить {image_file}\")\n",
    "        continue\n",
    "    \n",
    "    results = model(image_file)[0]\n",
    "\n",
    "    people_detected = [box for box in results.boxes if int(box.cls) == 0 and box.conf >= confidence_threshold]\n",
    "\n",
    "    TP = len(people_detected)\n",
    "    FN = max(0, people_true_number[image_number] - TP)\n",
    "    FP = 0  \n",
    "    TN = 0\n",
    "\n",
    "    results_array.append([image_number, people_true_number[image_number], TP, FP, FN])\n",
    "\n",
    "    for box in people_detected:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        confidence = box.conf.item()\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "        label = f\"Person: {confidence:.2f}\"\n",
    "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    image_resized = cv2.resize(image, output_size)\n",
    "\n",
    "    cv2.imshow(f\"Detected People - Image {image_number}\", image_resized)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    processed_image_path = f\"{image_processed_path}{image_number}_YOLO_80.jpg\"\n",
    "    cv2.imwrite(processed_image_path, image_resized)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Матрицы ошибок (TP, FP, FN, TN=0):\")\n",
    "for row in results_array:\n",
    "    print(row)"
   ],
   "id": "a00dfaf03c52d096",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/0.jpg: 384x640 5 persons, 70.8ms\n",
      "Speed: 2.9ms preprocess, 70.8ms inference, 30.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/1.jpg: 448x640 3 persons, 40.2ms\n",
      "Speed: 2.5ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/2.jpg: 416x640 2 persons, 2 cars, 1 potted plant, 40.8ms\n",
      "Speed: 2.4ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/3.jpg: 448x640 4 persons, 1 car, 24.7ms\n",
      "Speed: 2.7ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/4.jpg: 448x640 6 persons, 1 car, 24.1ms\n",
      "Speed: 2.7ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/5.jpg: 448x640 3 persons, 2 backpacks, 24.1ms\n",
      "Speed: 2.6ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/6.jpg: 416x640 4 persons, 23.8ms\n",
      "Speed: 2.6ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/7.jpg: 448x640 4 persons, 24.8ms\n",
      "Speed: 2.8ms preprocess, 24.8ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/8.jpg: 448x640 4 persons, 1 bottle, 1 chair, 2 laptops, 24.3ms\n",
      "Speed: 2.6ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /home/alexander/PycharmProjects/ImageProcessing/FirstTask/images1/images/9.jpg: 448x640 5 persons, 24.4ms\n",
      "Speed: 3.7ms preprocess, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Матрицы ошибок (TP, FP, FN, TN=0):\n",
      "[0, 5, 3, 0, 2]\n",
      "[1, 3, 2, 0, 1]\n",
      "[2, 4, 0, 0, 4]\n",
      "[3, 4, 4, 0, 0]\n",
      "[4, 6, 6, 0, 0]\n",
      "[5, 5, 2, 0, 3]\n",
      "[6, 4, 4, 0, 0]\n",
      "[7, 4, 3, 0, 1]\n",
      "[8, 4, 4, 0, 0]\n",
      "[9, 5, 3, 0, 2]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:03:08.220910Z",
     "start_time": "2025-04-20T10:03:08.215028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_TP = sum(row[2] for row in results_array)\n",
    "total_FP = sum(row[3] for row in results_array)\n",
    "total_FN = sum(row[4] for row in results_array)\n",
    "\n",
    "print(total_TP)\n",
    "print(total_FP)\n",
    "print(total_FN)"
   ],
   "id": "b19119c10c48fbd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "0\n",
      "13\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:03:08.298129Z",
     "start_time": "2025-04-20T10:03:08.284146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "precision = total_TP / (total_TP + total_FP) if (total_TP + total_FP) > 0 else 0\n",
    "recall = total_TP / (total_TP + total_FN) if (total_TP + total_FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1-Score: {f1_score:.3f}\")"
   ],
   "id": "57c6b5323c3b3856",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.000\n",
      "Recall: 0.705\n",
      "F1-Score: 0.827\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:02:10.383932Z",
     "start_time": "2025-04-20T10:02:10.378443Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e1c57fd200acccd5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
